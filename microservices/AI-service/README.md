# ğŸ¤– AI-Service

This microservice is responsible for generating AI-based email replies and learning user writing styles. It is part of a larger microservices-based AI email assistant system.

---

## ğŸ“Œ Responsibilities

- **Generate automated replies** to incoming emails using OpenAI GPT.
- **Analyze past emails** to learn a userâ€™s writing style, including tone, length, and complexity.
- **Respond to messages** from other services via HTTP and RabbitMQ.

---

## ğŸš€ Features

- Uses **OpenAI's GPT-4** for reply and tone analysis.
- Listens to **RabbitMQ** queue (`new-email`) for incoming email events.
- Exposes a **REST API endpoint** (`/learn-style`) for user style learning.
- Stores user tone preferences in a local JSON file (`user_tones.json`).

---

## ğŸ›  Technologies

- Python 3.10+
- OpenAI API
- FastAPI (for REST endpoint)
- Pika (RabbitMQ client)
- Docker

---

## ğŸ“ File Structure

```
AI-service/
â”œâ”€â”€ main.py              # Consumes email messages and handles Flask/FastAPI app
â”œâ”€â”€ ai_utils.py          # Handles AI reply generation
â”œâ”€â”€ style_learning.py    # Learns user tone from historical emails
â”œâ”€â”€ user_tones.json      # Stores user style profile (tone, length, complexity)
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ Dockerfile           # Container for deployment
```

---

## ğŸ§ª How It Works

### ğŸ” Email Reply Flow

1. `email-service` publishes a new email to RabbitMQ (`new-email` queue).
2. `AI-service` consumes the message.
3. It uses OpenAI GPT to generate a reply.
4. It sends the generated reply to `drafts-service` via a REST call.

### ğŸ§  Style Learning Flow

1. On user sign-up or import, another service can send a `POST` to `/learn-style` with past emails.
2. AI analyzes the emails and infers writing style.
3. It updates the userâ€™s style profile in `user_tones.json`.

---

## âš™ï¸ Running Locally

### 1. Clone the repo and install dependencies

```bash
pip install -r requirements.txt
```

### 2. Set your OpenAI API key

Create a `.env` file or set environment variable:

```env
OPENAI_API_KEY=sk-...
```

### 3. Run the service

```bash
python main.py
```

Or if youâ€™re using FastAPI:

```bash
uvicorn main:app --reload
```

---

## ğŸ³ Docker Usage

### Build the image

```bash
docker build -t ai-service .
```

### Run the container (in Docker network)

```bash
docker run --network my-network -e OPENAI_API_KEY=sk-... ai-service
```

---

## ğŸ”Œ Environment Variables

| Variable         | Required | Description            |
| ---------------- | -------- | ---------------------- |
| `OPENAI_API_KEY` | âœ…       | Your OpenAI secret key |

---

## ğŸ“« API Endpoints

### `POST /learn-style`

**Description**: Learns writing style based on past emails.

**Payload:**

```json
{
  "user_id": "1234",
  "emails": [
    { "body": "Thanks! Iâ€™ll check it out and get back to you." },
    { "body": "Sure, letâ€™s do 3 PM tomorrow." }
  ]
}
```

**Response:**

```json
{
  "user_id": "1234",
  "inferred_tone": "friendly",
  "length": "short",
  "complexity": "simple"
}
```

---

## ğŸ“ Related Services

- `email-service`: Provides new emails
- `drafts-service`: Stores generated replies
- `user-service`: (optional) Could replace local `user_tones.json`

---
